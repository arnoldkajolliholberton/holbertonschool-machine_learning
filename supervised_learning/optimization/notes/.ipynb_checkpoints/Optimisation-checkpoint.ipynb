{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c734f830",
   "metadata": {},
   "source": [
    "<img src=\"../holberton_logo.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "# Optimisation\n",
    "\n",
    "**Optimization is the process of finding the best solution to a problem**. In the context of Machine Learning, optimization is used to **find the best set of parameters for a model that minimizes a specific objective function**. The objective function is a measure of how well the model performs on a given task, such as classification or regression.\n",
    "\n",
    "Optimization is crucial in Machine Learning because it allows us to train models that can make accurate predictions on new data. Without optimization, it would be difficult to find the best set of parameters for a model, which would lead to poor performance and inaccurate predictions\n",
    "\n",
    "There are many different optimization algorithms that can be used in Machine Learning, such as gradient descent, stochastic gradient descent, and Adam. Each algorithm has its own strengths and weaknesses, and the choice of algorithm depends on the specific problem being solved and the characteristics of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85894268",
   "metadata": {},
   "source": [
    "## What is a hyperparameter\n",
    "\n",
    "A **hyperparameter is a parameter that is set before the training of a machine learning model begins**. These parameters **cannot be learned from the data during training, but instead, they must be set by the programmer** based on their domain knowledge, experience, and intuition.\n",
    "\n",
    "Hyperparameters *control the behavior of the training algorithm and the structure of the resulting model*. Some common hyperparameters (of a neural network) include the \n",
    "\n",
    "- learning rate\n",
    "\n",
    "- regularization strength\n",
    "\n",
    "- number of hidden layers\n",
    "\n",
    "- number of neurons per layer\n",
    "\n",
    "To find the best hyperparameters, a common approach is to perform a grid search or a randomized search over a range of values for each hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2c14f",
   "metadata": {},
   "source": [
    "## How and why do you normalize your input data?\n",
    "\n",
    "**Normalization is the process of scaling the input data to have zero mean and unit variance**. This is often done before training a machine learning model to improve performance and prevent numerical issues.\n",
    "\n",
    "<img src=\"figs/features.webp\" alt=\"logo\" width=\"300\"/>\n",
    "\n",
    "Normalization can improve performance by ensuring that all features are treated equally during training. This is because features with larger magnitudes can dominate the training process and overshadow other features. Normalization can also prevent numerical issues, such as overflow or underflow, that can occur when working with very large or very small numbers.\n",
    "\n",
    "There are several ways to normalize features\n",
    "\n",
    "#### 1. Standartization\n",
    "\n",
    "Standardisation replaces the values by their `Z` scores. This redistributes the features with their mean $\\mu = 0$ and standard deviation $\\sigma = 1$.\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - x_{mean}}{\\sigma}\n",
    "$$\n",
    "\n",
    "#### 2. Mean Normalisation\n",
    "\n",
    "This distribution will have values between `-1` and `1` with $\\mu = 0$.\n",
    "\n",
    "Standardisation and Mean Normalization can be used for algorithms that assumes zero centric data like Principal Component Analysis(PCA).\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - mean(x)}{max(x) - min(x)}\n",
    "$$\n",
    "\n",
    "### 3. Min Max Scaling\n",
    "\n",
    "This scaling brings the value between `0` and `1`.\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - min(x)}{max(x) - min(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed44610",
   "metadata": {},
   "source": [
    "## What is a saddle point?\n",
    "\n",
    "A saddle point is a critical point in the optimization landscape of a function where the gradient is zero, i.e., the **function has a stationary point** in one direction and a maximum or minimum point in another direction.\n",
    "\n",
    "At a saddle point, **the gradient descent algorithm will get stuck and cannot make progress towards the minimum**. This is because the gradient is zero, and the direction of steepest descent does not point towards the minimum. Saddle points are common in high-dimensional optimization problems, especially in deep neural networks.\n",
    "\n",
    "<img src=\"figs/saddlegradient.png\" alt=\"logo\" width=\"500\"/>\n",
    "\n",
    "\n",
    "To deal with saddle points, several techniques have been proposed, such as momentum-based optimization, adaptive learning rates, and second-order optimization methods. These techniques can help the optimization algorithm escape saddle points and converge to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284bbd5",
   "metadata": {},
   "source": [
    "## What is stochastic gradient descent?\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is an optimization algorithm commonly used in machine learning to minimize the loss function of a model. **It is a variant of the Gradient Descent algorithm that updates the model parameters based on the gradient of the loss function estimated from a randomly selected subset of the training data, rather than the full dataset**.\n",
    "\n",
    "The key idea behind SGD is to use a small subset of the training data, known as a mini-batch, to estimate the gradient of the loss function. This is computationally more efficient than computing the gradient on the entire dataset, especially when the dataset is large. After computing the gradient on the mini-batch, the algorithm updates the model parameters in the direction of the negative gradient.\n",
    "\n",
    "<img src=\"figs/sgd1.png\" alt=\"logo\" width=\"400\"/>\n",
    "\n",
    "The resulting plot clearly illustrates how stochastic gradient descent converges to the minimum point, but with a more erratic path due to the randomness in selecting the data points.\n",
    "\n",
    "\n",
    "To further improve the performance of SGD, several variants have been proposed, such as momentum-based SGD, Adagrad, RMSProp, and Adam. These variants adjust the learning rate or the update direction of the algorithm based on the history of the gradients, which can improve convergence and stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea469d5f",
   "metadata": {},
   "source": [
    "## What is mini-batch gradient descent?\n",
    "\n",
    "Mini-batch Gradient Descent is a variant of the Gradient Descent optimization algorithm used in machine learning. It is similar to Stochastic Gradient Descent (SGD) but updates the model parameters based on the gradient of the loss function estimated from a small random subset of the training data, known as a mini-batch, rather than a single training example.\n",
    "\n",
    "**The idea behind mini-batch Gradient Descent is to strike a balance between the efficiency of SGD and the stability of batch Gradient Descent, which computes the gradient on the entire training dataset**. By using mini-batches, the algorithm can make more frequent updates to the model parameters than batch Gradient Descent, which can speed up convergence and avoid getting stuck in local optima.\n",
    "\n",
    "<img src=\"figs/gradients.png\" alt=\"logo\" width=\"400\"/>\n",
    "\n",
    "\n",
    "**The size of the mini-batch is a hyperparameter that needs to be chosen carefully**. A larger mini-batch can provide a more accurate estimate of the gradient but may slow down the training process and require more memory. A smaller mini-batch can be faster and use less memory but may result in noisy updates to the model parameters\n",
    "\n",
    "\n",
    "#### Summary of Mini-Batch Gradient Descent Algorithm:\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "Load the neural network model from a saved path using TensorFlow. Get tensors and operations from the restored graph.\n",
    "\n",
    "##### Loop over Epochs:\n",
    "\n",
    "- For each epoch, calculate training and validation metrics.\n",
    "- Print the training and validation cost and accuracy after each epoch.\n",
    "\n",
    "##### Mini-Batch Processing:\n",
    "\n",
    "- Shuffle the training data and labels.\n",
    "- Calculate the number of batches based on the training data size and batch size.\n",
    "- Loop over each batch:\n",
    "    - Extract a mini-batch of data and labels.\n",
    "    - Run a training step with the mini-batch data using TensorFlow's sess.run() function.\n",
    "    - Optionally, print mini-batch results every 100 batches, including the cost and accuracy.\n",
    "- Save Model: Save the trained model to a specified path using TensorFlow's saver object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756eed1",
   "metadata": {},
   "source": [
    "## What is the moving average\n",
    "\n",
    "In the context of neural networks, a **moving average refers to a technique used to improve the stability of the network during training**. The moving average is applied to the network's weights or other trainable parameters, such as the mean and variance of the batch normalization layers, to smooth out fluctuations and reduce the impact of outliers in the training data.\n",
    "\n",
    "The basic idea behind the moving average is to **keep track of the past values of the parameters and update them based on a weighted average of the current and past values**. The weights are typically chosen to give more weight to the current value and less weight to the past values, with the goal of adapting to the changes in the training data while maintaining stability.\n",
    "\n",
    "The moving average is often used in conjunction with other optimization techniques, such as momentum-based stochastic gradient descent (SGD) and Adam optimizer, to improve the convergence and generalization performance of the network.\n",
    "\n",
    "<img src=\"figs/mavg.png\" alt=\"logo\" width=\"400\"/>\n",
    "\n",
    "\n",
    "#### Math behind it\n",
    "\n",
    "The **moving average calculates the weighted moving average of a dataset**. \n",
    "\n",
    "\n",
    "It iterates through the data points, updating the weighted average using the current data point and a weighting factor (`beta`). \n",
    "\n",
    "The formula used for the calculation is\n",
    "$$\n",
    "MA = (\\beta \\cdot w + (1 - \\beta) \\cdot d)\n",
    "$$\n",
    "\n",
    "- `w` represents the previous weighted average\n",
    "- `d` is the current data point\n",
    "- $\\beta$ is the weighting factor\n",
    "\n",
    "Additionally, the function applies bias correction to adjust the weighted average, ensuring accuracy over time. Formula for bias correction is\n",
    "\n",
    "$$\n",
    "w_{new} = \\frac{w}{1 - \\beta^{i+1}}\n",
    "$$\n",
    "\n",
    "- $w_{new}$ is the corrected weighted average\n",
    "- $w$ is the current weighted average\n",
    "- $\\beta$ is the weight parameter\n",
    "- `i` is the index of the current data point\n",
    "\n",
    "The resulting list contains the moving averages of the input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86700f",
   "metadata": {},
   "source": [
    "## What is gradient descent with momentum? \n",
    "\n",
    "**Gradient descent with momentum is an optimization algorithm that is used to speed up the convergence of the standard gradient descent algorithm**. The basic idea behind gradient descent with momentum is to accumulate a running average of the gradients over time and use this information to update the parameters of the model.\n",
    "\n",
    "In the standard gradient descent algorithm, the parameters are updated in the direction of the negative gradient of the cost function with respect to the parameters. However, the update can be quite noisy and fluctuate in different directions, which can slow down the convergence of the algorithm, especially in the presence of noisy or sparse data.\n",
    "\n",
    "In contrast, **gradient descent with momentum takes into account the previous gradients and uses a weighted average of the current and past gradients to update the parameters**. This helps to smooth out the update direction and speed up the convergence of the algorithm.\n",
    "\n",
    "The formula for updating the variables with momentum is:\n",
    "\n",
    "$$\n",
    "dW = \\beta_1 \\cdot v + (1 - \\beta_1) \\cdot grad\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $dW$ is the update term\n",
    "- $\\beta_1$ is the momentum weight\n",
    "- $v$ is the previous first moment of the variable\n",
    "- $grad$ is the gradient of the variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0876e715",
   "metadata": {},
   "source": [
    "## What is RMSProp?\n",
    "\n",
    "RMSProp stands for Root Mean Square Propagation, and it is an **optimization algorithm** commonly used in deep learning. RMSProp is designed to **handle the problem of diminishing learning rates**, which can lead to slow convergence or even a complete halt in the training process.\n",
    "\n",
    "#### Intuition in Simple Words\n",
    "\n",
    "- RMSProp changes how quickly the model learns for each part of the problem. If some parts are changing a lot, it slows down the learning to avoid overreacting. If other parts change slowly, it speeds up learning to not fall behind.\n",
    "- It does this by keeping track of how much each part has changed recently. If something changes a lot, it gets less attention. If something changes slowly, it gets more attention.\n",
    "- This helps the model learn steadily without getting too distracted by sudden changes or missing out on slower changes.\n",
    "\n",
    "#### Key Idea\n",
    "\n",
    "The basic idea behind RMSProp is to **maintain a moving average of the squared gradient for each weight in the network. This average is then used to scale the learning rate for each weight in the network**. In other words, the algorithm adapts the learning rate for each weight based on the magnitude of its gradients.\n",
    "\n",
    "RMSProp can be implemented in various deep learning frameworks such as TensorFlow, PyTorch, or Keras by using their built-in optimization algorithms that support RMSProp.\n",
    "\n",
    "\n",
    "Here are the key formulas\n",
    "\n",
    "##### Squared Gradient Calculation\n",
    "\n",
    "This formula calculates the squared gradient, which is a weighted sum of the squared gradients of previous time steps and the current gradient\n",
    "$$\n",
    "sq_{gradient} = \\beta_2 \\cdot s + (1 - \\beta_2) \\cdot grad^2\n",
    "$$\n",
    "\n",
    "- $sq_{gradient}$ represents the squared gradient, which is a weighted sum of the squared gradients of previous time steps and the current gradient\n",
    "- $\\beta_2$ is the RMSProp weight, controlling the contribution of the previous squared gradients\n",
    "- $s$ denotes the previous second moment of the variable\n",
    "- $grad$ is the gradient of the variable\n",
    "\n",
    "##### Variable update\n",
    "\n",
    "This formula updates the variable using the RMSProp update rule. It adjusts the variable based on the learning rate $\\alpha$, the gradient, the square root of the squared gradient, and a small constant \n",
    "$\\epsilon$ to avoid division by zero.\n",
    "\n",
    "$$\n",
    "updated_{variable} = var - \\frac{\\alpha \\cdot grad}{\\sqrt{sq_{gradient}} + \\epsilon}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ab23f",
   "metadata": {},
   "source": [
    "## What is Adam optimization?\n",
    "\n",
    "Adam optimization is an algorithm used for stochastic gradient descent that is widely used in deep learning for optimizing neural networks. Adam stands for Adaptive Moment Estimation and it combines the best aspects of two other popular optimization algorithms, namely RMSProp and momentum.\n",
    "\n",
    "\n",
    "#### Intuition in Simple Words\n",
    "\n",
    "- Adam combines the benefits of two other optimization techniques: RMSProp and Momentum.\n",
    "- Like RMSProp, it adjusts learning rates for different parameters, but it also keeps track of past gradients' momentum.\n",
    "- This combination allows Adam to adaptively adjust the learning rate for each parameter while efficiently handling sparse gradients and noisy data.\n",
    "\n",
    "\n",
    "Like RMSProp, Adam computes the moving average of the squared gradients to adapt the learning rate for each parameter. And like momentum, Adam keeps track of the exponentially decaying average of past gradients to smooth out the parameter updates.\n",
    "\n",
    "#### Key elements\n",
    "\n",
    "The algorithm is called Adam. It is not an acronym and is not written as ADAM. \n",
    "- The name Adam is derived from adaptive moment estimation.\n",
    "- Straightforward to implement.\n",
    "- Computationally efficient.\n",
    "- Little memory requirements.\n",
    "\n",
    "*The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients*\n",
    "\n",
    "\n",
    "The authors describe Adam as combining the advantages of two other extensions of stochastic gradient descent. Specifically:\n",
    "\n",
    "- **Adaptive Gradient Algorithm (AdaGrad)** that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n",
    "- **Root Mean Square Propagation (RMSProp)** that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\n",
    "\n",
    "Adam realizes the benefits of both AdaGrad and RMSProp.\n",
    "\n",
    "Instead of adapting the parameter learning rates based on the average first moment (the mean) as in RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance).\n",
    "\n",
    "<img src=\"figs/adam.png\" alt=\"adam\" width=\"600\"/>\n",
    "\n",
    "#### Mathematical reasoning and formulas\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "Adam optimizer initializes two variables, `v` and `s`, which represent the exponentially decaying average of past gradients and the exponentially decaying average of past squared gradients, respectively.\n",
    "\n",
    "##### Update rule\n",
    "\n",
    "At each iteration, Adam computes the exponentially decaying average of past gradients  `v` using a decay factor $\\beta_1$ and the exponentially decaying average of past squared gradients \n",
    "`s` using decay factor $\\beta_2$. These averages are updated with the current gradient of the variable.\n",
    "\n",
    "$$\n",
    "v_t = \\beta_1 \\cdot v_{t-1} + (1 - \\beta_1) \\cdot grad\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "s_t = \\beta_2 \\cdot s_{t-1} + (1 - \\beta_2) \\cdot grad^2\n",
    "$$\n",
    "\n",
    "##### Bias correction\n",
    "\n",
    "To compensate for the initialization bias towards zero, Adam performs bias correction by scaling the computed averages `v` and `s` by factors\n",
    "\n",
    "$$\n",
    "\\frac{1}{1 - \\beta_1^t}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{1}{1 - \\beta_2^t}\n",
    "$$\n",
    "\n",
    "where `t` is the current time step.\n",
    "\n",
    "##### Variable update\n",
    "\n",
    "Variable Update: Finally, Adam updates the variable using the corrected averages `v` and `s`, along with a small constant  $\\epsilon$ to prevent division by zero. The variable is updated in the direction of the gradient, with a learning rate $\\alpha$ scaled by the square root of the corrected squared gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b1bea",
   "metadata": {},
   "source": [
    "## What is learning rate decay?\n",
    "\n",
    "Learning rate decay is a technique used in optimization algorithms to decrease the learning rate during training. The idea behind learning rate decay is to gradually reduce the learning rate as training progresses, so that the updates become smaller and finer as the optimizer gets closer to the optimal solution. \n",
    "\n",
    "The main motivation behind learning rate decay is to balance the trade-off between convergence speed and convergence accuracy. A high learning rate can lead to fast convergence, but it can also result in overshooting the optimal solution and bouncing around it. A low learning rate can lead to a more accurate convergence, but it can also result in very slow convergence and getting stuck in local optima.\n",
    "\n",
    "<img src=\"figs/lr.png\" alt=\"adam\" width=\"600\"/>\n",
    "\n",
    "\n",
    "#### Learning rate decay \n",
    "\n",
    "is a technique used in training machine learning models to gradually reduce the learning rate over time. This can help fine-tune the model's parameters more precisely as training progresses. Here's a summary of the learning rate decay method implemented in the provided code\n",
    "\n",
    "#### Factor Calculation: \n",
    "\n",
    "The decay rate is applied to the learning rate based on the global step divided by the decay step. This factor increases over time as the global step increases.\n",
    "\n",
    "$$\n",
    "factor = 1 + decay \\cdot \\frac{global_{step}}{decay_{step}}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Learning Rate Scaling\n",
    "\n",
    "The original learning rate ($\\alpha$) is scaled by the inverse of the calculated factor. This scaled learning rate is then used for training the model.\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\alpha}{factor}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db57d6e",
   "metadata": {},
   "source": [
    "## What is batch normalization?\n",
    "\n",
    "Batch normalization is a technique used in deep learning to normalize the input of each layer of a neural network by adjusting and scaling the activations. The aim is to accelerate the training process and improve the overall performance of the network by reducing the internal covariate shift.\n",
    "\n",
    "The internal covariate shift refers to the change in the distribution of the input of each layer during training, which can slow down the convergence of the network and make it harder to optimize. By normalizing the input of each layer, batch normalization can help to reduce the internal covariate shift and make the training process more stable and efficient.\n",
    "\n",
    "Batch normalization works by computing the mean and variance of the activations of each layer over a mini-batch of inputs during training. Then, it centers and scales the activations using the mean and variance, and applies a linear transformation to the normalized inputs. The transformation includes learnable parameters that can be updated during backpropagation to optimize the network.\n",
    "\n",
    "<img src=\"figs/batch.webp\" alt=\"adam\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1535fde",
   "metadata": {},
   "source": [
    "### Happy coding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
